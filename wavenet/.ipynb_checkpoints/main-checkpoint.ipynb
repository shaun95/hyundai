{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torchsummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/data/datasets/hyundai\"\n",
    "ACC_PICKLE = os.path.join(PATH, \"stationary_accel_data.pickle\")\n",
    "SND_PICKLE = os.path.join(PATH, \"stationary_sound_data.pickle\")\n",
    "\n",
    "with open(ACC_PICKLE, \"rb\") as f:\n",
    "    acc_list = pickle.load(f)\n",
    "\n",
    "with open(SND_PICKLE, \"rb\") as f:\n",
    "    snd_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_window(data, window_size, hop_len):\n",
    "    #Slice data and concatenate them\n",
    "    #return them as numpy\n",
    "    windows = []\n",
    "    data_len = data.shape[0]\n",
    "    n_windows = int((data_len - window_size - hop_len) / hop_len)\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        window = data[i * hop_len : (i * hop_len) + window_size]\n",
    "        windows.append(window)\n",
    "    \n",
    "    return np.array(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA LOADED ACC : (82023, 1500, 12) SND : (82023, 1500, 8)\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 1500\n",
    "HOP_LEN = 256\n",
    "\n",
    "acc_data = np.concatenate(list(map(lambda x : slice_window(x, window_size=WINDOW_SIZE, hop_len=HOP_LEN), acc_list)), axis=0)\n",
    "snd_data = np.concatenate(list(map(lambda x : slice_window(x, window_size=WINDOW_SIZE, hop_len=HOP_LEN), snd_list)), axis=0)\n",
    "\n",
    "print(\"DATA LOADED ACC : {} SND : {}\".format(acc_data.shape, snd_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(PATH, \"stationary_acc_win_1500_hop_256.npy\"), acc_data)\n",
    "np.save(os.path.join(PATH, \"stationary_snd_win_1500_hop_256.npy\"), snd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mu_law_encoder(nn.Module):\n",
    "    def __init__(self, quantization_channels=256, rescale_factor=100):\n",
    "        super().__init__()\n",
    "        self.encoder = torchaudio.transforms.MuLawEncoding(quantization_channels=quantization_channels)\n",
    "        self.rescale_factor = rescale_factor\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x / self.rescale_factor\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class mu_law_decoder(nn.Module):\n",
    "    def init(self, quantization_channels=256, rescale_factor=100):\n",
    "        super().__init__()\n",
    "        self.quantization_channels = quantization_channels\n",
    "        self.rescale_factor = rescale_factor\n",
    "        self.decoder = torchaudio.transforms.MuLawDecoding(quantization_channels=quantization_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        x = x * self.rescale_factor\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavenet_Dataset(torch.utils.data.Dataset): \n",
    "  def __init__(self, x, y, receptive_field, transform=None):\n",
    "    self.x_data = x\n",
    "    self.y_data = y\n",
    "    \n",
    "    print(\"x shape : {}  y shape : {}\".format(self.x_data.shape, self.y_data.shape))\n",
    "    \n",
    "    self.transform = transform\n",
    "    self.receptive_field = receptive_field\n",
    "    \n",
    "    self.normalizer = torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx): \n",
    "    x = self.x_data[idx, :, :]\n",
    "    y = self.y_data[idx, self.receptive_field:, :]\n",
    "\n",
    "    if self.transform is not None:\n",
    "        x = self.transform(x).float()\n",
    "        y = self.transform(y)\n",
    "    \n",
    "    #x = self.normalizer(x) #normalize\n",
    "    x /= 255.\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape : (82023, 1500, 12)  y shape : (82023, 1500, 8)\n"
     ]
    }
   ],
   "source": [
    "BATCH = 16\n",
    "EPOCH = 30\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor(),\n",
    "                                    mu_law_encoder()\n",
    "                                    ])\n",
    "receptive_field = 1500 - 1474\n",
    "dataset = Wavenet_Dataset(x=acc_data, y=snd_data, receptive_field=receptive_field, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=BATCH)\n",
    "\n",
    "#Define Loss and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 1500, 12]), torch.Size([16, 1, 1474, 8]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANC_base_model(nn.Module):\n",
    "    def __init__(self, input_size=(1500, 12)):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.time = self.input_size[0]\n",
    "        self.input_chans = self.input_size[1]\n",
    "        \n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=self.input_chans, out_channels=256, kernel_size=7),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=256, out_channels=512, kernel_size=7),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, dilation=2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, dilation=2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, dilation=2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=512, out_channels=8, kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        self.decision = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels = 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels = 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels = 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels = 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels = 256, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.decision(x)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 8, 1474])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1            [-1, 256, 1494]          21,760\n",
      "       BatchNorm1d-2            [-1, 256, 1494]             512\n",
      "         LeakyReLU-3            [-1, 256, 1494]               0\n",
      "            Conv1d-4            [-1, 512, 1488]         918,016\n",
      "       BatchNorm1d-5            [-1, 512, 1488]           1,024\n",
      "         LeakyReLU-6            [-1, 512, 1488]               0\n",
      "            Conv1d-7            [-1, 512, 1484]         786,944\n",
      "       BatchNorm1d-8            [-1, 512, 1484]           1,024\n",
      "         LeakyReLU-9            [-1, 512, 1484]               0\n",
      "           Conv1d-10            [-1, 512, 1480]         786,944\n",
      "      BatchNorm1d-11            [-1, 512, 1480]           1,024\n",
      "        LeakyReLU-12            [-1, 512, 1480]               0\n",
      "           Conv1d-13            [-1, 512, 1476]         786,944\n",
      "      BatchNorm1d-14            [-1, 512, 1476]           1,024\n",
      "        LeakyReLU-15            [-1, 512, 1476]               0\n",
      "           Conv1d-16              [-1, 8, 1474]          12,296\n",
      "           Conv2d-17         [-1, 256, 8, 1474]           2,560\n",
      "      BatchNorm2d-18         [-1, 256, 8, 1474]             512\n",
      "        LeakyReLU-19         [-1, 256, 8, 1474]               0\n",
      "           Conv2d-20         [-1, 512, 8, 1474]       1,180,160\n",
      "      BatchNorm2d-21         [-1, 512, 8, 1474]           1,024\n",
      "        LeakyReLU-22         [-1, 512, 8, 1474]               0\n",
      "           Conv2d-23         [-1, 512, 8, 1474]       2,359,808\n",
      "      BatchNorm2d-24         [-1, 512, 8, 1474]           1,024\n",
      "        LeakyReLU-25         [-1, 512, 8, 1474]               0\n",
      "           Conv2d-26         [-1, 512, 8, 1474]       2,359,808\n",
      "      BatchNorm2d-27         [-1, 512, 8, 1474]           1,024\n",
      "        LeakyReLU-28         [-1, 512, 8, 1474]               0\n",
      "           Conv2d-29         [-1, 256, 8, 1474]       1,179,904\n",
      "================================================================\n",
      "Total params: 10,403,336\n",
      "Trainable params: 10,403,336\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 585.00\n",
      "Params size (MB): 39.69\n",
      "Estimated Total Size (MB): 624.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "layers = 10\n",
    "stacks = 1\n",
    "model = ANC_base_model()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "torchsummary.summary(model, (12, 1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit36598a2dc6be465b894ec45159f939a2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
