{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import pickle\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import models\n",
    "import utils\n",
    "import params\n",
    "from transition_S import Conv_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Settings\"\"\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\"\"\"Set Tensorboard Writer\"\"\"\n",
    "writer_path = os.path.join(os.getcwd(), \"wavenet_linear\")\n",
    "plot_save_path = os.path.join(os.getcwd(), \"wavenet_linear_plots\")\n",
    "\n",
    "if not os.path.isdir(writer_path):\n",
    "    os.mkdir(writer_path)\n",
    "\n",
    "if not os.path.isdir(plot_save_path):\n",
    "    os.mkdir(plot_save_path)\n",
    "\n",
    "writer = SummaryWriter(writer_path)\n",
    "\n",
    "\"\"\"HYPER PARAMETERS\"\"\"\n",
    "input_channels = 12\n",
    "output_channels = 8\n",
    "win_size = 512 # Set it after calculate receptive field is calcuted\n",
    "hop_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1            [-1, 64, 20000]           1,536\n",
      "      CausalConv1d-2            [-1, 64, 19999]               0\n",
      "     ResidualStack-3        [-1, 2, 128, 18976]               0\n",
      "              ReLU-4           [-1, 128, 18976]               0\n",
      "            Conv1d-5           [-1, 256, 18976]          33,024\n",
      "              ReLU-6           [-1, 256, 18976]               0\n",
      "            Conv1d-7           [-1, 256, 18976]          65,792\n",
      "           LastNet-8           [-1, 256, 18976]               0\n",
      "              ReLU-9           [-1, 128, 18976]               0\n",
      "           Conv1d-10           [-1, 256, 18976]          33,024\n",
      "             ReLU-11           [-1, 256, 18976]               0\n",
      "           Conv1d-12           [-1, 256, 18976]          65,792\n",
      "          LastNet-13           [-1, 256, 18976]               0\n",
      "             ReLU-14           [-1, 128, 18976]               0\n",
      "           Conv1d-15           [-1, 256, 18976]          33,024\n",
      "             ReLU-16           [-1, 256, 18976]               0\n",
      "           Conv1d-17           [-1, 256, 18976]          65,792\n",
      "          LastNet-18           [-1, 256, 18976]               0\n",
      "             ReLU-19           [-1, 128, 18976]               0\n",
      "           Conv1d-20           [-1, 256, 18976]          33,024\n",
      "             ReLU-21           [-1, 256, 18976]               0\n",
      "           Conv1d-22           [-1, 256, 18976]          65,792\n",
      "          LastNet-23           [-1, 256, 18976]               0\n",
      "             ReLU-24           [-1, 128, 18976]               0\n",
      "           Conv1d-25           [-1, 256, 18976]          33,024\n",
      "             ReLU-26           [-1, 256, 18976]               0\n",
      "           Conv1d-27           [-1, 256, 18976]          65,792\n",
      "          LastNet-28           [-1, 256, 18976]               0\n",
      "             ReLU-29           [-1, 128, 18976]               0\n",
      "           Conv1d-30           [-1, 256, 18976]          33,024\n",
      "             ReLU-31           [-1, 256, 18976]               0\n",
      "           Conv1d-32           [-1, 256, 18976]          65,792\n",
      "          LastNet-33           [-1, 256, 18976]               0\n",
      "             ReLU-34           [-1, 128, 18976]               0\n",
      "           Conv1d-35           [-1, 256, 18976]          33,024\n",
      "             ReLU-36           [-1, 256, 18976]               0\n",
      "           Conv1d-37           [-1, 256, 18976]          65,792\n",
      "          LastNet-38           [-1, 256, 18976]               0\n",
      "             ReLU-39           [-1, 128, 18976]               0\n",
      "           Conv1d-40           [-1, 256, 18976]          33,024\n",
      "             ReLU-41           [-1, 256, 18976]               0\n",
      "           Conv1d-42           [-1, 256, 18976]          65,792\n",
      "          LastNet-43           [-1, 256, 18976]               0\n",
      "================================================================\n",
      "Total params: 792,064\n",
      "Trainable params: 792,064\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.92\n",
      "Forward/backward pass size (MB): 1390.84\n",
      "Params size (MB): 3.02\n",
      "Estimated Total Size (MB): 1394.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load Model\"\"\"\n",
    "model = models.WaveNet(layer_size=10, stack_size=1).to(device)\n",
    "summary(model, (19999, 12))\n",
    "receptive_field = model.calc_receptive_fields(layer_size=10, stack_size=1)\n",
    "win_size += receptive_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================> Loading DATA <===================\n",
      "================> DATA Loaded Completed <===================\n"
     ]
    }
   ],
   "source": [
    "print(\"================> Loading DATA <===================\")\n",
    "#Load Data Pickle\n",
    "#with open(params.ACC_DATA, 'rb') as f:\n",
    "#    acc_pickle = pickle.load(f)\n",
    "\n",
    "#with open(params.SOUND_DATA, 'rb') as f:\n",
    "#    sound_pickle = pickle.load(f)\n",
    "\n",
    "#Load Dataset\n",
    "#acc_data = np.concatenate(list(map(lambda x : utils.slice_window(x, win_size, hop_len), acc_pickle)), axis=0)\n",
    "#sound_data = np.concatenate(list(map(lambda x : utils.slice_window(x, win_size, hop_len), sound_pickle)), axis=0)\n",
    "#np.save(os.path.join(params.PATH, \"train_acc_win_512_hop_128.npy\"), acc_data)\n",
    "#np.save(os.path.join(params.PATH, \"train_sound_win_512_hop_128.npy\"), sound_data)\n",
    "#acc_data = np.load(params.ACC_NPY)\n",
    "#sound_data = np.load(params.SOUND_NPY)\n",
    "acc_data = np.load(os.path.join(os.getcwd(), \"sample_acc.npy\"))\n",
    "sound_data = np.load(os.path.join(os.getcwd(), \"sample_sound.npy\"))\n",
    "print(\"================> DATA Loaded Completed <===================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================> DATA Preprocessing <===================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-454774bafd73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m transform = torchvision.transforms.Compose([\n\u001b[1;32m      5\u001b[0m                                     \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                     mu_encoder()])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWavenet_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msound_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceptive_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"================> DATA Preprocessed <===================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "\"\"\"PreProcess Data\"\"\"\n",
    "print(\"================> DATA Preprocessing <===================\")\n",
    "mu_encoder = utils.mu_law_encoder()\n",
    "transform = torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor(),\n",
    "                                    mu_encoder()])\n",
    "dataset = utils.Wavenet_Dataset(acc_data, sound_data, receptive_field, transform=transform)\n",
    "print(\"================> DATA Preprocessed <===================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 1\n",
    "EPOCH = 100\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "x, y = next(iter(dataloader))\n",
    "x = x.squeeze(1).float().to(device)\n",
    "y = y.squeeze(1).float().to(device)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "pred = model(x)\n",
    "\n",
    "s_filtered = Conv_S(pred, device=device)\n",
    "\n",
    "loss = loss_fn(s_filtered, y)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_filtered = Conv_S(pred, device=device)\n",
    "\n",
    "loss = loss_fn(s_filtered, y)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
